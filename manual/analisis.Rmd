# Análisis en `R`

Vamos a plantear una serie de análisis estadísticos con `R`, para los cuales vamos a utilizar los datos que vienen por defecto en las instalaciones de `R`, `iris`.

## Funciones descriptivas

### Función `summary()`

```{r, echo = TRUE}
summary(iris$Sepal.Length)
tapply(iris$Sepal.Length,
       INDEX = iris$Species,
       FUN = "summary")
```

### Función `quantile()`

```{r, echo = TRUE}
quantile(iris$Sepal.Length)
quantile(iris$Sepal.Length,
         probs = c(0, 0.2, 0.4, 0.6, 0.8, 1))
tapply(iris$Sepal.Length,
       INDEX = iris$Species, 
       FUN = "quantile")
```

### Función `fivenum()`

la función \emph{fivenum} devuelve los cinco números de Tukey (mínimo, primer cuartil, mediana, tercer cuartil, máximo) de los datos. 

```{r}
fivenum(iris$Sepal.Length)
tapply(iris$Sepal.Length,
       INDEX = iris$Species,
       FUN = "fivenum")
```

### Más funciones

Hay muchísimas funciones en `R` que permiten describir una distribución mediante estadísticos: `mean()`, `median()`, `IQR()`, `boxplot.stat()`, `range()`, `min()`, `max()`, ...

Hay otras funciones descriptivas, por ejemplo el coeficiente de asimetría, que no se encuentran en los paquetes básicos ..., pero podemos programarlas:

```{r}
skewness = function(x) {
	x <- x[!is.na(x)]
	m3 = mean((x-mean(x))^3)
	skew = m3/(sd(x)^3)
	skew
}
```

## Distribuciones de probabilidad

Un uso común es proporcionar un amplio conjunto de funciones estadísticas. Las funciones están previstas para evaluar la función de `densidad de probabilidad`, la función de `distribución acumulada` $P(X\le x)$ y la función `cuantil` (dado $q$, el valor más pequeño $x$ tal que $P(X\le x)> q$), y simular una distribución. 

En general, las funciones de probabilidad en `R` vienen dadas por el nombre por el que se las conoce en inglés (normal = `norm`, poisson = `pois`, binomial = `binom`, ...) y vienen precedidas por un prefijo según los valores a obtener, asì tenemos `d`, `dnorm` si queremos valores de una distribución normal, `p`, `pnorm` si queremos valores de probabilidad, `q`, `qnorm` si queremos valores cuantiles y `r`, `rnorm` si queremos valores aleatorios de una distribución normal. 

### Distribución Normal

Tenemos las siguientes opciones:

```{r, echo = TRUE, eval = FALSE}
dnorm(x, mean = 0, sd = 1, log = FALSE)
pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
qnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
rnorm(n, mean = 0, sd = 1)
```

```{r, echo = TRUE}
dnorm(5, mean = 3, sd = 1)
rnorm(5, mean = 5, sd = 5)
```

### Distribución Uniforme

Tenemos las siguientes opciones:

```{r, echo = TRUE, eval = FALSE}
dunif(x, min = 0, max = 1, log = FALSE)
punif(q, min = 0, max = 1, lower.tail = TRUE, log.p = FALSE)
qunif(p, min = 0, max = 1, lower.tail = TRUE, log.p = FALSE)
runif(n, min = 0, max = 1)
```

```{r, echo = TRUE}
runif(6, min = 10, max = 20)
qunif(c(0.25, 0.5, 0.75), min = 0, max = 1)
```

### Distribución de Poisson

Tenemos las siguientes opciones:

```{r, echo = TRUE, eval = FALSE}
dpois(x, lambda, log = FALSE)
ppois(q, lambda, lower.tail = TRUE, log.p = FALSE)
qpois(p, lambda, lower.tail = TRUE, log.p = FALSE)
rpois(n, lambda)
```

```{r, echo = TRUE}
rpois(6, lambda = 10)
qpois(c(0.25, 0.5, 0.75), lambda = 5)
```

### Más distribuciones

Y así con un montón de distribuciones más: `beta`, `binom`, `cauchy`, `chisq`, `exp`, `f`, `gamma`, `geom`, `hyper`, `lnorm`, `logis`, `nbinom`, `t`, `weibull`, `wilcox`, ...

## Test estadísticos

### Dos muestras

Uno de los análisis más comunes es la comparación de medias de dos poblaciones. vamos a realizar un an?lisis completo de una muestra en `R`.

Consideremos el siguiente conjunto de observaciones. Son los tiempos de espera en minutos hasta que nos traen la comida en dos restaurantes:

* **Restaurante A**: 1.40 3.23 1.60 0.91 2.28 2.49 0.74 0.51 3.15 2.47

* **Restaurante B**: 3.18 1.96 1.89 3.31 3.93 1.91 3.64 2.78 2.48 2.03

Lo primero, realizamos un análisis gráfico para ver los tiempos en los dos restaurantes.

```{r label = 'boxplot_tiempos_restaurante', echo = TRUE, fig.cap = 'Distribución de los tiempos de espera hasta ser atendido en cada restaurante.', fig.align = 'center', fig.path = 'figuras/manual/', fig.width = 6, fig.height = 6}
A <- c(1.40,3.23,1.60,0.91,2.28,2.49,0.74,0.51,3.15,2.47)
B <- c(3.18,1.96,1.89,3.31,3.93,1.91,3.64,2.78,2.48,2.03)

boxplot(A, B, col = c("red", "green"))
```

Tras una primera comprobaciòn visual, tenemos que los tiempos de espera no parecen iguales, pero ¿esta diferencia gráfica es significativa?, ¿podemos afirmar que los tiempos son diferentes y que las diferencias no son debidas a la dispersión propia de las medidas?

Para comprobar la igualdad de medias, realizamos un `t-test` no pareado.

```{r, echo = TRUE}
t.test(A, B, paired = FALSE)
```

```{r, echo = FALSE}
aux <- t.test(A, B, paired = FALSE)
```

La prueba indica que no hay diferencias significativas, asumiendo normalidad. Nos da un p-valor de `r format(aux$p.value, digits = 3)` por lo que no hay evidencias para rechazar la hipótesis nula $H_{0}$ y aceptamos que la verdadera diferencia de medias es igual a 0, es decir, tardan lo mismo en los dos restaurantes.

Pero ... ¿está bien aplicado el test? En la salida del test nos dice `Welch Two Sample t-test` y es que por defecto `R` no asume varianzas iguales en las muestras y aplica el `test de Welch`. Realizamos y `test F` para probar la igualdad de varianzas.

```{r, echo = TRUE}
var.test(A, B)
```

```{r, echo = FALSE}
aux <- var.test(A, B)
```

La prueba nos da un p-valor de `r format(aux$p.value, digits = 3)` por lo que no hay evidencias para rechazar la hipótesis $H_{0}$, es decir, asumimos que la razón de varianzas es igual a 1.

Por lo tanto, hemos aplicado mal el `t-test` ya que hemos asumido como hipótesis que ambas muestras tienen varianzas diferentes.

```{r, echo = TRUE}
t.test(A, B, paired = FALSE, var.equal = TRUE)
```

```{r, echo = FALSE}
aux <- t.test(A, B, paired = FALSE, var.equal = TRUE)
```

Ahora la prueba indica que hay diferencias significativas, asumiendo normalidad. Nos da un p-valor de `r format(aux$p.value, digits = 3)` por lo que hay evidencias para rechazar la hipótesis nula $H_{0}$ y aceptamos que la verdadera diferencia de medias no es igual a 0, es decir, no tardan lo mismo.
